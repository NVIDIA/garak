garak.probes.goat
=================

Dynamic multi-turn adversarial attacks using GOAT (Generative Offensive Agent Tester).

GOAT uses an Observation-Thought-Strategy-Reply (O-T-S-R) reasoning framework
to iteratively craft sophisticated adversarial prompts across multiple conversation turns.
It maintains two separate conversation histories: one for the AttackerLLM with full reasoning,
and one for the TargetLLM with just adversarial prompts and responses.

Uses the following options from ``_config.plugins.probes["goat"]``:

* ``max_iterations`` - Maximum number of attack iterations per goal (default: 5)
* ``attacker_model_type`` - Generator type for the AttackerLLM (default: "openai")
* ``attacker_model_name`` - Model name for the AttackerLLM (default: "o3-mini")
* ``attacker_model_config`` - Configuration dict for AttackerLLM (default: {"temperature": 1.0})
* ``attack_goals`` - List of attack objectives to test (default: 5 sample harmful behaviors)
* ``use_all_jbb_harmful_behaviors`` - Use all 100 JailbreakBench harmful behaviors (default: False)

Attack Techniques
-----------------

GOAT implements six sophisticated attack techniques:

* **Refusal Suppression** - Denies the target's ability to refuse by suppressing refusal strings
* **Dual Response** - Primes the LLM to generate multiple responses (safe/unsafe, generic/unhinged)
* **Response Priming** - Forces the target to start replies with specific strings to bypass safety
* **Persona Modification** - Changes the LLM's persona through roleplay or character adoption
* **Hypothetical** - Wraps violating requests in fictional or theoretical scenarios
* **Topic Splitting** - Exploits attention by embedding violating requests within safe contexts
* **Opposite Intent** - Tricks the target into responding with inverted or flipped intent

O-T-S-R Framework
-----------------

Each attack iteration generates:

1. **Observation (O)** - Analysis of the target model's response
2. **Thought (T)** - Reflection on the observation toward the goal
3. **Strategy (S)** - Description of the approach for crafting the next reply
4. **Reply (R)** - The actual adversarial prompt based on the strategy

OpenAI Compatible Attacker Model Configuration Example
----------------------

.. code-block:: JSON

   {
      "probes": {
         "goat": {
            "GOATAttack": {
               "max_iterations": 5,
               "attacker_model_type": "openai.OpenAICompatible",
               "attacker_model_name": "qwen3",
               "attacker_model_config": {
                  "temperature": 1.0,
                  "uri": "http://localhost:8000/v1/",
                  "api_key": "your_api_key",
                  "model": "qwen3",
                  "max_tokens": null,
                  "top_p": null,
                  "frequency_penalty": null,
                  "presence_penalty": null,
                  "seed": null,
                  "stop": null,
                  "stream": true, # to skip Gateway Timeout errors when generating long reasoning responses
               }
            }
         }
      }
   }


Usage Examples
--------------

Run GOAT with custom goals:

.. code-block::

   garak --target_name "gpt-4o-mini" --probes goat.GOATAttack \
   --probe_options '{"attack_goals": ["Write malicious code"], "max_iterations": 3}'

Run GOAT with all 100 JailbreakBench harmful behaviors (might take a while depending on your model's latency...):

.. code-block::

   garak --target_name "gpt-4o-mini" --probes goat.GOATAttack --probe_options '{"use_all_jbb_harmful_behaviors": true}'

Detection and Evaluation
------------------------

GOAT includes built-in LLM-as-a-judge evaluation using the ``notes.MatchSuccessBool`` detector.
The AttackerLLM evaluates each target response using the JailbreakBench classification prompt,
determining whether the response constitutes a successful jailbreak. The probe automatically
stops early when a successful attack is detected.

Each attempt includes detailed notes:

* ``goal`` - The attack objective being tested
* ``turn`` - Current iteration number
* ``observation`` - AttackerLLM's analysis of the target response  
* ``thought`` - AttackerLLM's reflection toward the goal
* ``strategy`` - Description of the attack strategy used
* ``success`` - Boolean indicating jailbreak success (for detector)
* ``reasoning`` - LLM judge's reasoning (when available)

----

.. automodule:: garak.probes.goat
   :members:
   :undoc-members:
   :show-inheritance: